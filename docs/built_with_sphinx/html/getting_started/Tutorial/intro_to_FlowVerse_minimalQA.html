<!DOCTYPE html>

<html :class="{'dark': darkMode === 'dark' || (darkMode === 'system' &amp;&amp; window.matchMedia('(prefers-color-scheme: dark)').matches)}" class="scroll-smooth" lang="en" x-data="{ darkMode: localStorage.getItem('darkMode') || localStorage.setItem('darkMode', 'system'), activeSection: '' }" x-init="$watch('darkMode', val =&gt; localStorage.setItem('darkMode', val))">
<head>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<meta charset="utf-8"/>
<meta content="white" media="(prefers-color-scheme: light)" name="theme-color"/>
<meta content="black" metia="(prefers-color-scheme: dark)" name="theme-color"/>
<meta content="Docutils 0.19: https://docutils.sourceforge.io/" name="generator"/>
<title>Introducing the FlowVerse with a Simple Q&amp;A Flow | aiFlows  documentation</title>
<meta content="Introducing the FlowVerse with a Simple Q&amp;A Flow | aiFlows  documentation" property="og:title"/>
<meta content="Introducing the FlowVerse with a Simple Q&amp;A Flow | aiFlows  documentation" name="twitter:title"/>
<link href="../../_static/pygments.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/theme.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="../../_static/flows_logo_round.png" rel="icon"/>
<link href="../../search.html" rel="search" title="Search"/>
<link href="../../genindex.html" rel="index" title="Index"/>
<script>
    <!-- Prevent Flash of wrong theme -->
      const userPreference = localStorage.getItem('darkMode');
      let mode;
      if (userPreference === 'dark' || window.matchMedia('(prefers-color-scheme: dark)').matches) {
        mode = 'dark';
        document.documentElement.classList.add('dark');
      } else {
        mode = 'light';
      }
      if (!userPreference) {localStorage.setItem('darkMode', mode)}
    </script>
</head>
<body :class="{ 'overflow-hidden': showSidebar }" class="min-h-screen font-sans antialiased bg-background text-foreground" x-data="{ showSidebar: false }">
<div @click.self="showSidebar = false" class="fixed inset-0 z-50 overflow-hidden bg-background/80 backdrop-blur-sm" x-cloak="" x-show="showSidebar"></div><div class="relative flex flex-col min-h-screen" id="page"><a class="absolute top-0 left-0 z-[100] block bg-background p-4 text-xl transition -translate-x-full opacity-0 focus:translate-x-0 focus:opacity-100" href="#content">
      Skip to content
    </a><header class="sticky top-0 z-40 w-full border-b shadow-sm border-border supports-backdrop-blur:bg-background/60 bg-background/95 backdrop-blur"><div class="container flex items-center h-14">
<div class="hidden mr-4 md:flex">
<a class="flex items-center mr-6" href="../../index.html"><span class="hidden font-bold sm:inline-block text-clip whitespace-nowrap">aiFlows  documentation</span>
</a></div><button @click="showSidebar = true" class="inline-flex items-center justify-center h-10 px-0 py-2 mr-2 text-base font-medium transition-colors rounded-md hover:text-accent-foreground hover:bg-transparent md:hidden" type="button">
<svg aria-hidden="true" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M152.587 825.087q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440Zm0-203.587q-19.152 0-32.326-13.174T107.087 576q0-19.152 13.174-32.326t32.326-13.174h320q19.152 0 32.326 13.174T518.087 576q0 19.152-13.174 32.326T472.587 621.5h-320Zm0-203.587q-19.152 0-32.326-13.174t-13.174-32.326q0-19.152 13.174-32.326t32.326-13.174h440q19.152 0 32.326 13.174t13.174 32.326q0 19.152-13.174 32.326t-32.326 13.174h-440ZM708.913 576l112.174 112.174q12.674 12.674 12.674 31.826t-12.674 31.826Q808.413 764.5 789.261 764.5t-31.826-12.674l-144-144Q600 594.391 600 576t13.435-31.826l144-144q12.674-12.674 31.826-12.674t31.826 12.674q12.674 12.674 12.674 31.826t-12.674 31.826L708.913 576Z"></path>
</svg>
<span class="sr-only">Toggle navigation menu</span>
</button>
<div class="flex items-center justify-between flex-1 space-x-2 sm:space-x-4 md:justify-end">
<div class="flex-1 w-full md:w-auto md:flex-none"><form @keydown.k.window.meta="$refs.search.focus()" action="../../search.html" class="relative flex items-center group" id="searchbox" method="get">
<input aria-label="Search the docs" class="inline-flex items-center font-medium transition-colors bg-transparent focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 ring-offset-background border border-input hover:bg-accent focus:bg-accent hover:text-accent-foreground focus:text-accent-foreground hover:placeholder-accent-foreground py-2 px-4 relative h-9 w-full justify-start rounded-[0.5rem] text-sm text-muted-foreground sm:pr-12 md:w-40 lg:w-64" id="search-input" name="q" placeholder="Search ..." type="search" x-ref="search"/>
<kbd class="pointer-events-none absolute right-1.5 top-2 hidden h-5 select-none text-muted-foreground items-center gap-1 rounded border border-border bg-muted px-1.5 font-mono text-[10px] font-medium opacity-100 sm:flex group-hover:bg-accent group-hover:text-accent-foreground">
<span class="text-xs">⌘</span>
    K
  </kbd>
</form>
</div>
<nav class="flex items-center space-x-1">
<button @click="darkMode = darkMode === 'light' ? 'dark' : 'light'" class="relative inline-flex items-center justify-center px-0 text-sm font-medium transition-colors rounded-md hover:bg-accent hover:text-accent-foreground h-9 w-9" type="button">
<svg class="absolute transition-all scale-100 rotate-0 dark:-rotate-90 dark:scale-0" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 685q45.456 0 77.228-31.772Q589 621.456 589 576q0-45.456-31.772-77.228Q525.456 467 480 467q-45.456 0-77.228 31.772Q371 530.544 371 576q0 45.456 31.772 77.228Q434.544 685 480 685Zm0 91q-83 0-141.5-58.5T280 576q0-83 58.5-141.5T480 376q83 0 141.5 58.5T680 576q0 83-58.5 141.5T480 776ZM80 621.5q-19.152 0-32.326-13.174T34.5 576q0-19.152 13.174-32.326T80 530.5h80q19.152 0 32.326 13.174T205.5 576q0 19.152-13.174 32.326T160 621.5H80Zm720 0q-19.152 0-32.326-13.174T754.5 576q0-19.152 13.174-32.326T800 530.5h80q19.152 0 32.326 13.174T925.5 576q0 19.152-13.174 32.326T880 621.5h-80Zm-320-320q-19.152 0-32.326-13.174T434.5 256v-80q0-19.152 13.174-32.326T480 130.5q19.152 0 32.326 13.174T525.5 176v80q0 19.152-13.174 32.326T480 301.5Zm0 720q-19.152 0-32.326-13.17Q434.5 995.152 434.5 976v-80q0-19.152 13.174-32.326T480 850.5q19.152 0 32.326 13.174T525.5 896v80q0 19.152-13.174 32.33-13.174 13.17-32.326 13.17ZM222.174 382.065l-43-42Q165.5 327.391 166 308.239t13.174-33.065q13.435-13.674 32.587-13.674t32.065 13.674l42.239 43q12.674 13.435 12.555 31.706-.12 18.272-12.555 31.946-12.674 13.674-31.445 13.413-18.772-.261-32.446-13.174Zm494 494.761-42.239-43q-12.674-13.435-12.674-32.087t12.674-31.565Q686.609 756.5 705.38 757q18.772.5 32.446 13.174l43 41.761Q794.5 824.609 794 843.761t-13.174 33.065Q767.391 890.5 748.239 890.5t-32.065-13.674Zm-42-494.761Q660.5 369.391 661 350.62q.5-18.772 13.174-32.446l41.761-43Q728.609 261.5 747.761 262t33.065 13.174q13.674 13.435 13.674 32.587t-13.674 32.065l-43 42.239q-13.435 12.674-31.706 12.555-18.272-.12-31.946-12.555Zm-495 494.761Q165.5 863.391 165.5 844.239t13.674-32.065l43-42.239q13.435-12.674 32.087-12.674t31.565 12.674Q299.5 782.609 299 801.38q-.5 18.772-13.174 32.446l-41.761 43Q231.391 890.5 212.239 890t-33.065-13.174ZM480 576Z"></path>
</svg>
<svg class="absolute transition-all scale-0 rotate-90 dark:rotate-0 dark:scale-100" fill="currentColor" height="24" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 936q-151 0-255.5-104.5T120 576q0-138 90-239.5T440 218q25-3 39 18t-1 44q-17 26-25.5 55t-8.5 61q0 90 63 153t153 63q31 0 61.5-9t54.5-25q21-14 43-1.5t19 39.5q-14 138-117.5 229T480 936Zm0-80q88 0 158-48.5T740 681q-20 5-40 8t-40 3q-123 0-209.5-86.5T364 396q0-20 3-40t8-40q-78 32-126.5 102T200 576q0 116 82 198t198 82Zm-10-270Z"></path>
</svg>
</button>
</nav>
</div>
</div>
</header>
<div class="flex-1"><div class="container flex-1 items-start md:grid md:grid-cols-[220px_minmax(0,1fr)] md:gap-6 lg:grid-cols-[240px_minmax(0,1fr)] lg:gap-10"><aside :aria-hidden="!showSidebar" :class="{ 'translate-x-0': showSidebar }" class="fixed inset-y-0 left-0 md:top-14 z-50 md:z-30 bg-background md:bg-transparent transition-all duration-100 -translate-x-full md:translate-x-0 ml-0 p-6 md:p-0 md:-ml-2 md:h-[calc(100vh-3.5rem)] w-5/6 md:w-full shrink-0 overflow-y-auto border-r border-border md:sticky" id="left-sidebar">
<a class="!justify-start text-sm md:!hidden bg-background" href="../../index.html"><span class="font-bold text-clip whitespace-nowrap">aiFlows  documentation</span>
</a>
<div class="relative overflow-hidden md:overflow-auto my-4 md:my-0 h-[calc(100vh-8rem)] md:h-auto">
<div class="overflow-y-auto h-full w-full relative pr-6"><nav class="table w-full min-w-full my-6 lg:my-8">
<p class="caption" role="heading"><span class="caption-text">Table of Contents</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction/index.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Getting Started</a></li>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../../contributing_info/contribute_index.html">Contribution Guide<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2"><a class="reference internal" href="../../contributing_info/automating_documentation_flow.html">Automating the documentation of a Flow on  the FlowVerse</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../contributing_info/coding_standards.html">Coding Standards</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../contributing_info/contributing_to_FlowVerse.html">Recommended Workflow for Contributing to a Flow on the FlowVerse</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../contributing_info/contributing_to_aiFlows.html">Contributing to aiFlows Library (for bug fixes and adding features)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../contributing_info/finding_collaborators.html">Looking for Collaborators ?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../contributing_info/index.html">Contribute</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../contributing_info/license_info.html">Licence Info: Frequently Asked Questions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../contributing_info/recognition_info.html">Publicizing Your Work</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../citation/index.html">Citation</a></li>
<li class="toctree-l1" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../../source/modules.html">aiflows<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l2" x-data="{ expanded: $el.classList.contains('current') ? true : false }"><a :class="{ 'expanded' : expanded }" @click="expanded = !expanded" class="reference internal expandable" href="../../source/aiflows.html">aiflows package<button @click.prevent.stop="expanded = !expanded" type="button"><span class="sr-only"></span><svg fill="currentColor" height="18px" stroke="none" viewbox="0 0 24 24" width="18px" xmlns="http://www.w3.org/2000/svg"><path d="M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z"></path></svg></button></a><ul x-show="expanded">
<li class="toctree-l3"><a class="reference internal" href="../../source/aiflows.backends.html">aiflows.backends package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../source/aiflows.base_flows.html">aiflows.base_flows package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../source/aiflows.data_transformations.html">aiflows.data_transformations package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../source/aiflows.datasets.html">aiflows.datasets package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../source/aiflows.flow_cache.html">aiflows.flow_cache package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../source/aiflows.flow_launchers.html">aiflows.flow_launchers package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../source/aiflows.flow_verse.html">aiflows.flow_verse package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../source/aiflows.history.html">aiflows.history package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../source/aiflows.interfaces.html">aiflows.interfaces package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../source/aiflows.messages.html">aiflows.messages package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../source/aiflows.prompt_template.html">aiflows.prompt_template package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../source/aiflows.utils.html">aiflows.utils package</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
<button @click="showSidebar = false" class="absolute md:hidden right-4 top-4 rounded-sm opacity-70 transition-opacity hover:opacity-100" type="button">
<svg class="h-4 w-4" fill="currentColor" height="24" stroke="none" viewbox="0 96 960 960" width="24" xmlns="http://www.w3.org/2000/svg">
<path d="M480 632 284 828q-11 11-28 11t-28-11q-11-11-11-28t11-28l196-196-196-196q-11-11-11-28t11-28q11-11 28-11t28 11l196 196 196-196q11-11 28-11t28 11q11 11 11 28t-11 28L536 576l196 196q11 11 11 28t-11 28q-11 11-28 11t-28-11L480 632Z"></path>
</svg>
</button>
</aside>
<main class="relative py-6 lg:gap-10 lg:py-8 xl:grid xl:grid-cols-[1fr_300px]">
<div class="w-full min-w-0 mx-auto">
<nav aria-label="breadcrumbs" class="flex items-center mb-4 space-x-1 text-sm text-muted-foreground">
<a class="overflow-hidden text-ellipsis whitespace-nowrap hover:text-foreground" href="../../index.html">
<span class="hidden md:inline">aiFlows  documentation</span>
<svg aria-label="Home" class="md:hidden" fill="currentColor" height="18" stroke="none" viewbox="0 96 960 960" width="18" xmlns="http://www.w3.org/2000/svg">
<path d="M240 856h120V616h240v240h120V496L480 316 240 496v360Zm-80 80V456l320-240 320 240v480H520V696h-80v240H160Zm320-350Z"></path>
</svg>
</a>
<div class="mr-1">/</div><span aria-current="page" class="font-medium text-foreground overflow-hidden text-ellipsis whitespace-nowrap">Introducing the FlowVerse with a Simple Q&amp;A Flow</span>
</nav>
<div id="content" role="main">
<section id="introducing-the-flowverse-with-a-simple-q-a-flow">
<h1>Introducing the FlowVerse with a Simple Q&amp;A Flow<a class="headerlink" href="#introducing-the-flowverse-with-a-simple-q-a-flow" title="Permalink to this heading">¶</a></h1>
<p><strong>Prerequisites:</strong> setting up your API keys (see <a class="reference internal" href="setting_up_aiFlows.html"><span class="std std-doc">setting_up_aiFlows.md</span></a>), <a class="reference internal" href="atomic_flow.html"><span class="std std-doc">Atomic Flow Tutorial</span></a></p>
<p>This guide introduces the FlowVerse via an example: <a class="reference external" href="https://github.com/epfl-dlab/aiflows/tree/main/examples/minimal%20QA/">minimalQA</a>. The guide is organized in two sections:</p>
<ol class="arabic simple">
<li><p><a class="reference internal" href="#section-1-whats-the-flowverse"><span class="xref myst">Section 1:</span></a> What’s the FlowVerse?</p></li>
<li><p><a class="reference internal" href="#section-2-crafting-a-simple-qa-flow-with-the-chatflowmodule"><span class="xref myst">Section 2:</span></a> Crafting a Simple Q&amp;A Flow with the ChatFlowModule</p></li>
</ol>
<section id="by-the-tutorial-s-end-i-will-have">
<h2>By the Tutorial’s End, I Will Have…<a class="headerlink" href="#by-the-tutorial-s-end-i-will-have" title="Permalink to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#by-the-tutorial-s-end-i-will-have'">¶</a></h2>
<ul class="simple">
<li><p>Gained an understanding of the FlowVerse and its significance</p></li>
<li><p>Acquired the skills to retrieve flows from the FlowVerse</p></li>
<li><p>Successfully developed my initial flow by incorporating a FlowVerse flow</p></li>
<li><p>Created a Simple Q&amp;A flow capable of managing user-assistant interactions with a Language Model (LLM) through an API</p></li>
<li><p>Familiarized myself with the fundamental parameters of the <code class="docutils literal notranslate"><span class="pre">ChatAtomicFlow</span></code></p></li>
</ul>
</section>
<section id="section-1-what-s-the-flowverse">
<h2>Section 1: What’s the FlowVerse ?<a class="headerlink" href="#section-1-what-s-the-flowverse" title="Permalink to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#section-1-what-s-the-flowverse'">¶</a></h2>
<p>The FlowVerse is the hub of flows created and shared by our amazing community for everyone to use! These flows are usually shared on Hugging Face with the intention of being reused by others. Explore our Flows on the FlowVerse <a class="reference external" href="https://huggingface.co/aiflows">here</a>!</p>
</section>
<section id="section-2-crafting-a-simple-q-a-flow-with-the-chatflowmodule">
<h2>Section 2: Crafting a Simple Q&amp;A Flow with the ChatFlowModule<a class="headerlink" href="#section-2-crafting-a-simple-q-a-flow-with-the-chatflowmodule" title="Permalink to this heading" x-intersect.margin.0%.0%.-70%.0%="activeSection = '#section-2-crafting-a-simple-q-a-flow-with-the-chatflowmodule'">¶</a></h2>
<p>In this section, we’ll guide you through the creation of a simple Q&amp;A flow — a single user-assitant interaction with a LLM. We’ll achieve this by leveraging the <code class="docutils literal notranslate"><span class="pre">ChatAtomicFlow</span></code> from the <a class="reference external" href="https://huggingface.co/aiflows/ChatFlowModule">ChatFlowModule</a> in the FlowVerse. The <code class="docutils literal notranslate"><span class="pre">ChatAtomicFlow</span></code> seamlessly interfaces with an LLM through an API, generating textual responses for textual input. Powered by the LiteLLM library in the backend, <code class="docutils literal notranslate"><span class="pre">ChatAtomicFlow</span></code> supports various API providers; explore the full list <a class="reference external" href="https://docs.litellm.ai/docs/providers">here</a>.</p>
<p>For an in-depth understanding of <code class="docutils literal notranslate"><span class="pre">ChatAtomicFlow</span></code>, refer to its <a class="reference external" href="https://huggingface.co/aiflows/ChatFlowModule/blob/main/README.md">FlowCard (README)</a>.
Note that all the code referenced from this point onwards can be found <a class="reference external" href="https://github.com/epfl-dlab/aiflows/tree/main/examples/minimal%20QA/">here</a></p>
<p>Let’s dive in without further delay!</p>
<p>First thing to do is to fetch the <code class="docutils literal notranslate"><span class="pre">ChatFlowModule</span></code> from the FlowVerse (see <a class="reference external" href="https://github.com/epfl-dlab/aiflows/tree/main/examples/minimal%20QA/run_qa_flow.py">run_qa_flow.py</a> to see all the code):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">aiflows</span> <span class="kn">import</span> <span class="n">flow_verse</span>
<span class="c1"># ~~~ Load Flow dependecies from FlowVerse ~~~</span>
<span class="n">dependencies</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s2">"url"</span><span class="p">:</span> <span class="s2">"aiflows/ChatFlowModule"</span><span class="p">,</span> <span class="s2">"revision"</span><span class="p">:</span> <span class="s2">"297c90d08087d9ff3139521f11d1a48d7dc63ed4"</span><span class="p">},</span>
<span class="p">]</span>
<span class="n">flow_verse</span><span class="o">.</span><span class="n">sync_dependencies</span><span class="p">(</span><span class="n">dependencies</span><span class="p">)</span>
</pre></div>
</div>
<p>Let’s break this down:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dependencies</span></code> is a list of dictionaries (in this case, there’s only one) indicating which FlowModules we want to pull from the FlowVerse. The dictionary contains two key-value pairs:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">url</span></code>: Specifies the URL where the flow can be found on Hugging Face. Here, the URL is <code class="docutils literal notranslate"><span class="pre">aiflows/ChatFlowModule</span></code>, where <code class="docutils literal notranslate"><span class="pre">aiflows</span></code> is the name of our organization on Hugging Face (or the username of a user hosting their flow on Hugging Face), and <code class="docutils literal notranslate"><span class="pre">ChatFlowModule</span></code> is the name of the FlowModule containing the <code class="docutils literal notranslate"><span class="pre">ChatAtomicFlow</span></code> on the FlowVerse. Note that the <code class="docutils literal notranslate"><span class="pre">url</span></code> is literally the address of the <code class="docutils literal notranslate"><span class="pre">ChatFlowModule</span></code> on Hugging Face (excluding the https://huggingface.co/). So if you type https://huggingface.co/aiflows/ChatFlowModule in your browser, you will find the Flow.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">revision</span></code>: Represents the revision id (i.e., the full commit hash) of the commit we want to fetch. Note that if you set <code class="docutils literal notranslate"><span class="pre">revision</span></code> to <code class="docutils literal notranslate"><span class="pre">main</span></code>, it will fetch the latest commit on the main branch.</p></li>
</ul>
</li>
</ul>
<p>Now that we’ve fetched the <code class="docutils literal notranslate"><span class="pre">ChatAtomicFlowModule</span></code> from the FlowVerse, we can start creating our Flow.</p>
<p>The configuration for our flow is available in <a class="reference external" href="https://github.com/epfl-dlab/aiflows/tree/main/examples/minimal%20QA/simpleQA.yaml">simpleQA.yaml</a>. We will now break it down into chunks and explain its various parameters. Note that the flow is instantiated from its default configuration, so we are only defining the parameters we wish to override here. The default configuration can be found <a class="reference external" href="https://huggingface.co/aiflows/ChatFlowModule/blob/main/ChatAtomicFlow.yaml">here</a></p>
<p>Let’s start with the input and output interface:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">input_interface</span><span class="p">:</span><span class="w"> </span><span class="c1"># Connector between the "input data" and the Flow</span>
<span class="w">  </span><span class="nt">_target_</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">aiflows.interfaces.KeyInterface</span>
<span class="w">  </span><span class="nt">additional_transformations</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">_target_</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">aiflows.data_transformations.KeyMatchInput</span><span class="w"> </span><span class="c1"># Pass the input parameters specified by the flow</span>

<span class="nt">output_interface</span><span class="p">:</span><span class="w"> </span><span class="c1"># Connector between the Flow's output and the caller</span>
<span class="w">  </span><span class="nt">_target_</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">aiflows.interfaces.KeyInterface</span>
<span class="w">  </span><span class="nt">keys_to_rename</span><span class="p">:</span>
<span class="w">    </span><span class="nt">api_output</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">answer</span><span class="w"> </span><span class="c1"># Rename the api_output to answer</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">input_interface</span></code> specifies the expected keys in the input data dictionary passed to our flow.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">output_interface</span></code>  outlines the expected keys in the output data dictionary produced by our flow.</p></li>
</ul>
<p>Now let’s look at the flow’s configuration:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">flow</span><span class="p">:</span><span class="w"> </span><span class="c1"># Overrides the ChatAtomicFlow config</span>
<span class="w">  </span><span class="nt">_target_</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">flow_modules.aiflows.ChatFlowModule.ChatAtomicFlow.instantiate_from_default_config</span>

<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s">"SimpleQA_Flow"</span>
<span class="w">  </span><span class="nt">description</span><span class="p">:</span><span class="w"> </span><span class="s">"A</span><span class="nv"> </span><span class="s">flow</span><span class="nv"> </span><span class="s">that</span><span class="nv"> </span><span class="s">answers</span><span class="nv"> </span><span class="s">questions."</span>
</pre></div>
</div>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">_target_</span></code> parameter specifies the instantiation method for our flow. In this instance, we’re using it to instantiate the <code class="docutils literal notranslate"><span class="pre">ChatAtomicFlow</span></code> from <a class="reference external" href="https://huggingface.co/aiflows/ChatFlowModule/blob/main/ChatAtomicFlow.yaml">its default configuration file</a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code> and <code class="docutils literal notranslate"><span class="pre">description</span></code>: self-explanatory parameters</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="c1"># ~~~ Input interface specification ~~~</span>
<span class="w">  </span><span class="nt">input_interface_non_initialized</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">"question"</span>
</pre></div>
</div>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">input_interface_non_initialized</span></code> parameter in our configuration specifies the keys expected in the input data dictionary when the <code class="docutils literal notranslate"><span class="pre">ChatAtomicFlow</span></code> is called for the first time (i.e., when the system prompt is constructed). Essentially, it serves a role similar to the regular <code class="docutils literal notranslate"><span class="pre">input_interface</span></code>. The distinction becomes apparent when you require different inputs for the initial query compared to subsequent queries. For instance, in ReAct, the first time you query the LLM, the input is provided by a human, such as a question. In subsequent queries, the input comes from the execution of a tool (e.g. a query to wikipedia). In ReAct’s case, these two scenarios are distinguished by <code class="docutils literal notranslate"><span class="pre">ChatAtomicFlow</span></code>’s <code class="docutils literal notranslate"><span class="pre">input_interface_non_initialized</span></code> and <code class="docutils literal notranslate"><span class="pre">input_interface_initialized</span></code> parameters. For this tutorial, as we’re creating a simple Q&amp;A flow performing a single user-assistant interaction with an LLM, we never use <code class="docutils literal notranslate"><span class="pre">input_interface_initialized</span></code> (which is why it’s not defined in the configuration).</p></li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="c1"># ~~~ backend model parameters ~~</span>
<span class="w">  </span><span class="nt">backend</span><span class="p">:</span>
<span class="w">    </span><span class="nt">_target_</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">aiflows.backends.llm_lite.LiteLLMBackend</span>
<span class="w">    </span><span class="nt">api_infos</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">???</span>
<span class="w">    </span><span class="nt">model_name</span><span class="p">:</span>
<span class="w">      </span><span class="nt">openai</span><span class="p">:</span><span class="w"> </span><span class="s">"gpt-3.5-turbo"</span>
<span class="w">      </span><span class="nt">azure</span><span class="p">:</span><span class="w"> </span><span class="s">"azure/gpt-4"</span>

<span class="w">    </span><span class="c1"># ~~~ generation_parameters ~~</span>
<span class="w">    </span><span class="nt">n</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">max_tokens</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3000</span>
<span class="w">    </span><span class="nt">temperature</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.3</span>

<span class="w">    </span><span class="nt">top_p</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.2</span>
<span class="w">    </span><span class="nt">frequency_penalty</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="w">    </span><span class="nt">presence_penalty</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
</pre></div>
</div>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">backend</span></code> is a dictionary containing parameters specific to the LLM. These parameters include:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">api_infos</span></code> Your API information (which will be passed later for privacy reasons).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">model_name</span></code> A dictionary with key-item pairs, where keys correspond to the <code class="docutils literal notranslate"><span class="pre">backend_used</span></code> attribute of the <code class="docutils literal notranslate"><span class="pre">ApiInfo</span></code> class for the chosen backend, and values represent the desired model for that backend. Model selection depends on the provided <code class="docutils literal notranslate"><span class="pre">api_infos</span></code>. Additional models can be added for different backends, following LiteLLM’s naming conventions (refer to LiteLLM’s supported providers and model names <a class="reference external" href="https://docs.litellm.ai/docs/providers">here</a>). For instance, with an Anthropic API key and a desire to use “claude-2,” one would check Anthropic’s model details <a class="reference external" href="https://docs.litellm.ai/docs/providers/anthropic#model-details">here</a>. As “claude-2” is named the same in LiteLLM, the <code class="docutils literal notranslate"><span class="pre">model_name</span></code> dictionary would be updated as follows:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">backend</span><span class="p">:</span>
<span class="nt">_target_</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">aiflows.backends.llm_lite.LiteLLMBackend</span>
<span class="nt">api_infos</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">???</span>
<span class="nt">model_name</span><span class="p">:</span>
<span class="w">  </span><span class="nt">openai</span><span class="p">:</span><span class="w"> </span><span class="s">"gpt-3.5-turbo"</span>
<span class="w">  </span><span class="nt">azure</span><span class="p">:</span><span class="w"> </span><span class="s">"azure/gpt-4"</span>
<span class="w">  </span><span class="nt">anthropic</span><span class="p">:</span><span class="w"> </span><span class="s">"claude-2"</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">n</span></code>,<code class="docutils literal notranslate"><span class="pre">max_tokens</span></code>,<code class="docutils literal notranslate"><span class="pre">top_p</span></code>, <code class="docutils literal notranslate"><span class="pre">frequency_penalty</span></code>, <code class="docutils literal notranslate"><span class="pre">presence_penalty</span></code> are generation parameters for LiteLLM’s completion function (refer to all possible generation parameters <a class="reference external" href="https://docs.litellm.ai/docs/completion/input#input-params-1">here</a>).</p></li>
</ul>
</li>
</ul>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="c1"># ~~~ Prompt specification ~~~</span>
<span class="w">  </span><span class="nt">system_message_prompt_template</span><span class="p">:</span>
<span class="w">    </span><span class="nt">_target_</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">aiflows.prompt_template.JinjaPrompt</span>
<span class="w">    </span><span class="nt">template</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|2-</span>
<span class="w">      </span><span class="no">You are a helpful chatbot that truthfully answers questions.</span>
<span class="w">    </span><span class="nt">input_variables</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[]</span>
<span class="w">    </span><span class="nt">partial_variables</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">{}</span>

<span class="w">  </span><span class="nt">init_human_message_prompt_template</span><span class="p">:</span>
<span class="w">    </span><span class="nt">_target_</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">aiflows.prompt_template.JinjaPrompt</span>
<span class="w">    </span><span class="nt">template</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">|2-</span>
<span class="w">      </span><span class="no">Answer the following question: {{question}}</span>
<span class="w">    </span><span class="nt">input_variables</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">[</span><span class="s">"question"</span><span class="p p-Indicator">]</span>
<span class="w">    </span><span class="nt">partial_variables</span><span class="p">:</span><span class="w"> </span><span class="p p-Indicator">{}</span>
</pre></div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">system_message_prompt_template</span></code>: This is the system prompt template passed to the LLM.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">init_human_message_prompt_template</span></code>: This is the user prompt template passed to the LLM the first time the flow is called. It includes the following parameters:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">template</span></code> The prompt template in Jinja format.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">input_variables</span></code> The input variables of the prompt. For instance, in our case, the prompt <code class="docutils literal notranslate"><span class="pre">template</span></code>
is “Answer the following question: {{question}},” and our <code class="docutils literal notranslate"><span class="pre">input_variables</span></code>  is “question.” Before querying the LLM, the prompt <code class="docutils literal notranslate"><span class="pre">template</span></code> is rendered by placing the input variable “question” in the placeholder “{{question}}” of the prompt <code class="docutils literal notranslate"><span class="pre">template</span></code>.  It’s worth noting that  <code class="docutils literal notranslate"><span class="pre">input_interface_non_initialized</span> <span class="pre">==</span> <span class="pre">input_variables</span></code>. This alignment is intentional, as they are passed as input_variables to the <code class="docutils literal notranslate"><span class="pre">init_human_message_prompt_template</span></code> to render the <code class="docutils literal notranslate"><span class="pre">template</span></code></p></li>
</ul>
</li>
</ul>
<p>Now that our configuration file is set up, we can proceed to call our flow. Begin by configuring your API information. Below is an example using an OpenAI key, along with examples for other API providers (in comment):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span> <span class="c1"># ~~~ Set the API information ~~~</span>
<span class="c1"># OpenAI backend</span>

<span class="n">api_information</span> <span class="o">=</span> <span class="p">[</span><span class="n">ApiInfo</span><span class="p">(</span><span class="n">backend_used</span><span class="o">=</span><span class="s2">"openai"</span><span class="p">,</span> <span class="n">api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">getenv</span><span class="p">(</span><span class="s2">"OPENAI_API_KEY"</span><span class="p">))]</span>

<span class="c1"># # Azure backend</span>
<span class="c1"># api_information = [ApiInfo(backend_used = "azure",</span>
<span class="c1">#                           api_base = os.getenv("AZURE_API_BASE"),</span>
<span class="c1">#                           api_key = os.getenv("AZURE_OPENAI_KEY"),</span>
<span class="c1">#                           api_version =  os.getenv("AZURE_API_VERSION") )]</span>

<span class="c1"># # Anthropic backend</span>
<span class="c1">#api_information = [ApiInfo(backend_used= "anthropic",api_key = os.getenv("ANTHROPIC_API_KEY"))]</span>

</pre></div>
</div>
<p>Next, load the YAML configuration, insert your API information, and define the <code class="docutils literal notranslate"><span class="pre">flow_with_interfaces</span></code> dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="n">cfg_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">root_dir</span><span class="p">,</span> <span class="s2">"simpleQA.yaml"</span><span class="p">)</span>
<span class="n">cfg</span> <span class="o">=</span> <span class="n">read_yaml_file</span><span class="p">(</span><span class="n">cfg_path</span><span class="p">)</span>
<span class="c1"># put api information in config (done like this for privacy reasons)</span>
<span class="n">cfg</span><span class="p">[</span><span class="s2">"flow"</span><span class="p">][</span><span class="s2">"backend"</span><span class="p">][</span><span class="s2">"api_infos"</span><span class="p">]</span> <span class="o">=</span> <span class="n">api_information</span>

<span class="c1"># ~~~ Instantiate the Flow ~~~</span>
<span class="n">flow_with_interfaces</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">"flow"</span><span class="p">:</span> <span class="n">hydra</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">instantiate</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"flow"</span><span class="p">],</span> <span class="n">_recursive_</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">_convert_</span><span class="o">=</span><span class="s2">"partial"</span><span class="p">),</span>
    <span class="s2">"input_interface"</span><span class="p">:</span> <span class="p">(</span>
        <span class="kc">None</span>
        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"input_interface"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="k">else</span> <span class="n">hydra</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">instantiate</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"input_interface"</span><span class="p">],</span> <span class="n">_recursive_</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="p">),</span>
    <span class="s2">"output_interface"</span><span class="p">:</span> <span class="p">(</span>
        <span class="kc">None</span>
        <span class="k">if</span> <span class="n">cfg</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"output_interface"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="kc">None</span>
        <span class="k">else</span> <span class="n">hydra</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">instantiate</span><span class="p">(</span><span class="n">cfg</span><span class="p">[</span><span class="s2">"output_interface"</span><span class="p">],</span> <span class="n">_recursive_</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="p">),</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Finally, run the flow with <code class="docutils literal notranslate"><span class="pre">FlowLauncher</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># ~~~ Get the data ~~~</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"id"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">"question"</span><span class="p">:</span> <span class="s2">"Who was the NBA champion in 2023?"</span><span class="p">}</span>  <span class="c1"># This can be a list of samples</span>

<span class="c1"># ~~~ Run inference ~~~</span>
<span class="n">path_to_output_file</span> <span class="o">=</span> <span class="kc">None</span>
<span class="c1"># path_to_output_file = "output.jsonl"  # Uncomment this line to save the output to disk</span>

<span class="n">_</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> <span class="n">FlowLauncher</span><span class="o">.</span><span class="n">launch</span><span class="p">(</span>
    <span class="n">flow_with_interfaces</span><span class="o">=</span><span class="n">flow_with_interfaces</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">path_to_output_file</span><span class="o">=</span><span class="n">path_to_output_file</span>
<span class="p">)</span>

<span class="c1"># ~~~ Print the output ~~~</span>
<span class="n">flow_output_data</span> <span class="o">=</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="n">flow_output_data</span><span class="p">)</span>
</pre></div>
</div>
<p>The full example is available <a class="reference external" href="https://github.com/epfl-dlab/aiflows/tree/main/examples/minimal%20QA/">here</a> and can be executed as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>examples/minimal<span class="se">\ </span>QA/
python<span class="w"> </span>run_qa_flow.py<span class="w"> </span>
</pre></div>
</div>
<p>Upon running, the answer is similar to the following:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="o">[{</span><span class="s1">'answer'</span>:<span class="w"> </span><span class="s2">"I'm sorry, but as an AI language model, I don't have access to real-time information or the ability to predict future events. As of now, I cannot provide you with the answer to who the NBA champion was in 2023. I recommend checking reliable sports news sources or conducting an internet search for the most up-to-date information."</span><span class="o">}]</span>
</pre></div>
</div>
<p>To learn how to obtain information on the 2023 NBA Champion using Flows, refer to the next tutorial <a class="reference internal" href="reAct.html"><span class="std std-doc">ReAct</span></a>, a Flow that provides <code class="docutils literal notranslate"><span class="pre">ChatAtomicFlow</span></code> to tools like search engines!</p>
<p>Additionally, the <a class="reference external" href="https://github.com/epfl-dlab/aiflows/tree/main/examples/minimal%20QA/">minimal QA</a> folder contains other examples using <code class="docutils literal notranslate"><span class="pre">ChatAtomicFlow</span></code> such as:</p>
<ul>
<li><p>Running a <a class="reference external" href="https://github.com/epfl-dlab/aiflows/tree/main/examples/minimal%20QA/run_qa_flow_w_demonstrations.py">Flow with Demonstrations</a> (encouraging the LLM to finshis answers with “my sire”). To run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>examples/minimal<span class="se">\ </span>QA/
python<span class="w"> </span>run_qa_flow_w_demonstrations.py
</pre></div>
</div>
</li>
<li><p>Running the <a class="reference external" href="https://github.com/epfl-dlab/aiflows/tree/main/examples/minimal%20QA/run_qa_flow_multithreaded.py">Simple Q&amp;A flow in a multithreaded fashion</a> in order answer multiple questions with mulitple API_keys or providers. To run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>examples/minimal<span class="se">\ </span>QA/
python<span class="w"> </span>run_qa_flow_multithreaded.py
</pre></div>
</div>
</li>
</ul>
<hr class="docutils"/>
<p><strong>Next Tutorial:</strong> <a class="reference internal" href="reAct.html"><span class="std std-doc">ReAct Tutorial</span></a></p>
</section>
</section>
</div></div><aside class="hidden text-sm xl:block" id="right-sidebar">
<div class="sticky top-16 -mt-10 max-h-[calc(var(100vh)-5rem)] overflow-y-auto pt-6 space-y-2"><p class="font-medium">On this page</p>
<ul>
<li><a :data-current="activeSection === '#by-the-tutorial-s-end-i-will-have'" class="reference internal" href="#by-the-tutorial-s-end-i-will-have">By the Tutorial’s End, I Will Have…</a></li>
<li><a :data-current="activeSection === '#section-1-what-s-the-flowverse'" class="reference internal" href="#section-1-what-s-the-flowverse">Section 1: What’s the FlowVerse ?</a></li>
<li><a :data-current="activeSection === '#section-2-crafting-a-simple-q-a-flow-with-the-chatflowmodule'" class="reference internal" href="#section-2-crafting-a-simple-q-a-flow-with-the-chatflowmodule">Section 2: Crafting a Simple Q&amp;A Flow with the ChatFlowModule</a></li>
</ul>
</div>
</aside>
</main>
</div>
</div><footer class="py-6 border-t border-border md:py-0">
<div class="container flex flex-col items-center justify-between gap-4 md:h-24 md:flex-row">
<div class="flex flex-col items-center gap-4 px-8 md:flex-row md:gap-2 md:px-0">
<p class="text-sm leading-loose text-center text-muted-foreground md:text-left">© 2023 Built with <a class="font-medium underline underline-offset-4" href="https://www.sphinx-doc.org" rel="noreferrer">Sphinx 6.2.1</a></p>
</div>
</div>
</footer>
</div>
<script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
<script src="../../_static/doctools.js"></script>
<script src="../../_static/sphinx_highlight.js"></script>
<script src="../../_static/clipboard.min.js"></script>
<script src="../../_static/copybutton.js"></script>
<script defer="defer" src="../../_static/theme.js"></script>
</body>
</html>